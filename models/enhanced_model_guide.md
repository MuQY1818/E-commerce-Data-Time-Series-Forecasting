# 增强版时序预测模型指南

## 模型架构概述

增强版模型在简化版模型的基础上，添加了更复杂的组件，同时保持数值稳定性。主要组件如下：

1. **输入投影层**：将输入特征投影到更高维的隐藏空间
2. **卷积层**：捕获局部时间模式
3. **残差连接**：加速训练并防止梯度消失
4. **LSTM层**：捕获长期依赖关系
5. **注意力机制**：关注序列中的重要部分
6. **全连接层**：最终预测输出

整体架构图：
```
输入 → 投影层 → 卷积层 + 残差连接 → LSTM → 注意力机制 → 全连接层 → 输出
```

## 模型特点

### 1. 数值稳定性保障

增强版模型在保持复杂性的同时，加入了多重数值稳定性保障：

- 每个组件后添加数值检查，及时发现并处理NaN和Inf值
- 使用更稳健的权重初始化方法（Xavier、Orthogonal初始化）
- 适当的梯度裁剪和学习率调度
- 残差连接减少梯度消失问题

### 2. 注意力机制

模型使用了自注意力机制，具有以下特点：

- 能够动态关注时间序列中最相关的部分
- 使用缩放点积注意力，提高训练稳定性
- 包含查询(Q)、键(K)、值(V)三个投影矩阵，增强表达能力

### 3. 卷积特征提取

使用一维卷积网络处理时间序列数据：

- 捕获局部时间模式和特征关系
- 使用BatchNorm和LeakyReLU提高训练稳定性和非线性表达能力
- 与残差连接结合，保持信息流动

## 使用指南

### 前提条件

确保已经成功运行过简化版模型(`simplified_model.py`)，因为增强版模型会导入其中的一些函数。

### 训练步骤

1. 运行增强版模型:
   ```bash
   python enhanced_model.py
   ```

2. 模型将自动:
   - 加载并预处理数据
   - 创建并训练增强版模型
   - 评估模型性能
   - 保存训练结果和预测

### 超参数调优

主要可调参数及其建议值:

- `hidden_size`: 128-256，根据数据复杂度调整
- `num_layers`: 2-3，层数越多捕获的特征越复杂，但训练难度也越大
- `dropout`: 0.3-0.5，根据过拟合程度调整
- `learning_rate`: 0.0001-0.001，建议从小值开始
- `batch_size`: 16-32，根据GPU内存调整

### 结果解释

训练完成后，查看以下文件了解模型性能:

- `enhanced_prediction_results.csv`: 预测结果和真实值
- 可视化图表: 包含损失曲线、预测vs真实值、误差分布等

## 进一步优化建议

1. **特征工程**: 
   - 添加更多领域特定特征
   - 尝试滚动统计特征（如7天移动平均）
   - 添加外部因素（如节假日、促销活动）

2. **架构改进**:
   - 尝试不同类型的注意力机制（如多头注意力）
   - 添加门控机制如GRU
   - 探索时间卷积网络(TCN)或Transformer结构

3. **训练策略**:
   - 尝试不同的优化器（如RAdam, Lion）
   - 使用学习率预热和周期性学习率
   - 采用对抗训练提高泛化能力

## 常见问题

**Q: 模型训练过程中仍然出现NaN值怎么办？**

A: 尝试以下措施:
- 进一步降低学习率至0.0001
- 增加梯度裁剪阈值至0.1
- 检查数据中是否仍有极端值

**Q: 模型训练速度较慢？**

A: 可以:
- 减少序列长度(seq_length)
- 减小batch_size
- 简化模型（减少层数或隐藏单元）
- 尝试混合精度训练

**Q: 模型预测未能捕捉极端峰值？**

A: 考虑:
- 使用不同的损失函数，如Huber损失或加权MSE
- 在特殊时间点（如双11）添加特征标志
- 尝试分位数回归以更好地捕捉分布尾部 